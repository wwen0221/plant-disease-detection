{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc714e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = \"plant-disease-detection-tutorial\"\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, framework=\"image-classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3train = \"s3://plant-disease-detection-tutorial/medium-tutorial/s3train/\"\n",
    "s3validation = \"s3://plant-disease-detection-tutorial/medium-tutorial/s3validation/\"\n",
    "s3train_lst = \"s3://plant-disease-detection-tutorial/medium-tutorial/s3train_lst/\"\n",
    "s3validation_lst = \"s3://plant-disease-detection-tutorial/medium-tutorial/s3validation_lst/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = 18\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,224,224\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "num_training_samples = 10000\n",
    "# specify the number of output classes\n",
    "num_classes = 10\n",
    "# batch size for training\n",
    "mini_batch_size = 128\n",
    "# number of epochs\n",
    "epochs = 6\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "# report top_5 accuracy\n",
    "top_k = 5\n",
    "# resize image before training\n",
    "resize = 256\n",
    "# period to store model parameters (in number of epochs), in this case, we will save parameters from epoch 2, 4, and 6\n",
    "checkpoint_frequency = 2\n",
    "# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be\n",
    "# initialized with pre-trained weights\n",
    "use_pretrained_model = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "s3 = boto3.client(\"s3\", aws_access_key_id='',\n",
    "    aws_secret_access_key='')\n",
    "# create unique job name\n",
    "job_name_prefix = \"sagemaker-imageclassification-notebook\"\n",
    "timestamp = time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = {\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": training_image, \"TrainingInputMode\": \"File\"},\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, job_name_prefix)},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.g4dn.xlarge\", \"VolumeSizeInGB\": 50},\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"top_k\": str(top_k),\n",
    "        \"resize\": str(resize),\n",
    "        \"checkpoint_frequency\": str(checkpoint_frequency),\n",
    "        \"use_pretrained_model\": str(use_pretrained_model),\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 360000},\n",
    "    # Training data should be inside a subdirectory called \"train\"\n",
    "    # Validation data should be inside a subdirectory called \"validation\"\n",
    "    # The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3train,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3validation,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"train_lst\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3train_lst,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation_lst\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3validation_lst,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "print(\"Training job name: {}\".format(job_name))\n",
    "print(\n",
    "    \"\\nInput Data Location: {}\".format(\n",
    "        training_params[\"InputDataConfig\"][0][\"DataSource\"][\"S3DataSource\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name=\"sagemaker\")\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(\"Training job current status: {}\".format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter(\"training_job_completed_or_stopped\").wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info[\"TrainingJobStatus\"]\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print(\"Training failed to start\")\n",
    "    # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)[\"FailureReason\"]\n",
    "    print(\"Training failed with the following error: {}\".format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info[\"TrainingJobStatus\"]\n",
    "print(\"Training job ended with status: \" + status)\n",
    "print(training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03194126",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sage = boto3.Session().client(service_name=\"sagemaker\")\n",
    "\n",
    "timestamp = time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "model_name = \"image-classification-model\" + timestamp\n",
    "print(model_name)\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(model_data)\n",
    "\n",
    "hosting_image = image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, framework=\"image-classification\"\n",
    ")\n",
    "\n",
    "primary_container = {\n",
    "    \"Image\": hosting_image,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "batch_job_name = \"image-classification-model\" + timestamp\n",
    "batch_input = s3validation + \"001.Apple___Apple_scab/\"\n",
    "request = {\n",
    "    \"TransformJobName\": batch_job_name,\n",
    "    \"ModelName\": model_name,\n",
    "    \"MaxConcurrentTransforms\": 16,\n",
    "    \"MaxPayloadInMB\": 6,\n",
    "    \"BatchStrategy\": \"SingleRecord\",\n",
    "    \"TransformOutput\": {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, batch_job_name)},\n",
    "    \"TransformInput\": {\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": batch_input}},\n",
    "        \"ContentType\": \"application/x-image\",\n",
    "        \"SplitType\": \"None\",\n",
    "        \"CompressionType\": \"None\",\n",
    "    },\n",
    "    \"TransformResources\": {\"InstanceType\": \"ml.m5.large\", \"InstanceCount\": 1},\n",
    "}\n",
    "\n",
    "print(\"Transform job name: {}\".format(batch_job_name))\n",
    "print(\"\\nInput Data Location: {}\".format(batch_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "sagemaker.create_transform_job(**request)\n",
    "\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "while True:\n",
    "    response = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = response[\"TransformJobStatus\"]\n",
    "    if status == \"Completed\":\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == \"Failed\":\n",
    "        message = response[\"FailureReason\"]\n",
    "        print(\"Transform failed with the following error: {}\".format(message))\n",
    "        raise Exception(\"Transform job failed\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker list-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "object_categories = [\n",
    "    \"001.Apple___Apple_scab\",\n",
    "    \"002.Apple___Black_rot\",\n",
    "    \"003.Apple___Cedar_apple_rust\",\n",
    "    \"004.Apple___healthy\",\n",
    "    \"005.Blueberry___healthy\",\n",
    "    \"006.Cherry_(including_sour)___healthy\",\n",
    "    \"007.Cherry_(including_sour)___Powdery_mildew\",\n",
    "    \"008.Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\n",
    "    \"009.Corn_(maize)___Common_rust_\",\n",
    "    \"010.Corn_(maize)___healthy\"\n",
    "]\n",
    "\n",
    "\n",
    "def list_objects(s3_client, bucket, prefix):\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    objects = [content[\"Key\"] for content in response[\"Contents\"]]\n",
    "    return objects\n",
    "\n",
    "\n",
    "def get_label(s3_client, bucket, prefix):\n",
    "    filename = prefix.split(\"/\")[-1]\n",
    "    s3_client.download_file(bucket, prefix, filename)\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        index = np.argmax(data[\"prediction\"])\n",
    "        probability = data[\"prediction\"][index]\n",
    "    print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(probability))\n",
    "    return object_categories[index], probability\n",
    "\n",
    "print(batch_input)\n",
    "\n",
    "inputs = list_objects(s3_client, 'plant-disease-detection-tutorial', 'medium-tutorial/s3validation/001.Apple___Apple_scab/')\n",
    "print(\"Sample inputs: \" + str(inputs[:2]))\n",
    "\n",
    "outputs = list_objects(s3_client, bucket, batch_job_name + \"/output\")\n",
    "print(\"Sample output: \" + str(outputs[:2]))\n",
    "\n",
    "# Check prediction result of the first 2 images\n",
    "[get_label(s3_client, bucket, prefix) for prefix in outputs[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + \"-epc-\" + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint configuration name: {}\".format(endpoint_config_name))\n",
    "print(\"Endpoint configuration arn:  {}\".format(endpoint_config_response[\"EndpointConfigArn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "endpoint_name = job_name_prefix + \"-ep-\" + timestamp\n",
    "print(\"Endpoint name: {}\".format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    \"EndpointName\": endpoint_name,\n",
    "    \"EndpointConfigName\": endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print(\"EndpointArn = {}\".format(endpoint_response[\"EndpointArn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b779617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response[\"EndpointStatus\"]\n",
    "print(\"EndpointStatus = {}\".format(status))\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter(\"endpoint_in_service\").wait(EndpointName=endpoint_name)\n",
    "finally:\n",
    "    resp = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "    print(\"Create endpoint ended with status: \" + status)\n",
    "\n",
    "    if status != \"InService\":\n",
    "        message = sagemaker.describe_endpoint(EndpointName=endpoint_name)[\"FailureReason\"]\n",
    "        print(\"Training failed with the following error: {}\".format(message))\n",
    "        raise Exception(\"Endpoint creation did not succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29035cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
